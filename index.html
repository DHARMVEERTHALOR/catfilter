<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Ultimate Smooth Cat Face Filter</title>
<style>
body { margin:0; background:#000; display:flex; justify-content:center; align-items:center; height:100vh; overflow:hidden; }
canvas { position:absolute; top:0; left:0; }
#controls { position:fixed; bottom:20px; left:50%; transform:translateX(-50%); display:flex; gap:10px; z-index:1000; }
button { padding:10px 16px; font-size:15px; border:none; border-radius:10px; background:#ff8fb3; color:#fff; cursor:pointer; box-shadow:0 4px 12px rgba(0,0,0,0.4); }
#message { position:fixed; top:12px; left:12px; color:#fff; font-family:system-ui,Segoe UI,Roboto,Arial; background:rgba(0,0,0,0.4); padding:8px 12px; border-radius:8px; }
</style>
</head>
<body>

<div id="message">Allow camera & mic when prompted. Best on HTTPS.</div>
<video id="video" autoplay playsinline style="display:none;"></video>
<canvas id="canvas"></canvas>

<div id="controls">
  <button id="start">Start/Pause</button>
  <button id="stop">Stop & Download</button>
</div>

<!-- TensorFlow.js & Face Landmarks Detection -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
let stream, animationFrame, recording=false, mediaRecorder, recordedChunks=[], model;
let audioCtx, analyser, dataArray;

// Images
const catMask = new Image(); catMask.src = 'cat-mask.png';
const mouthFrames = []; for (let i=1;i<=3;i++){ const img=new Image(); img.src=`mouth${i}.png`; mouthFrames.push(img); }
const ears = new Image(); ears.src = 'ears.png';
const eyes = new Image(); eyes.src = 'eyes.png';

// Utility
function lerp(a,b,t){ return a + (b-a)*t; }

// Resize canvas
function resizeCanvas(){
  canvas.width = video.videoWidth || 480;
  canvas.height = video.videoHeight || 854;
  if (!video.videoWidth){
    canvas.width = Math.min(window.innerWidth, 480);
    canvas.height = Math.round(canvas.width * 16/9);
  }
}

// Load face model
async function loadModel(){
  model = await faceLandmarksDetection.load(
    faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh,
    { maxFaces: 1 }
  );
}

// Init camera + audio
async function initCameraAndAudio(){
  try{
    stream = await navigator.mediaDevices.getUserMedia({ video:{ facingMode:'user', width:480, height:854 }, audio:true });
    video.srcObject = stream;

    mediaRecorder = new MediaRecorder(stream, { mimeType:'video/webm' });
    mediaRecorder.ondataavailable = e => { if (e.data.size>0) recordedChunks.push(e.data); };
    mediaRecorder.onstop = downloadVideo;

    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const source = audioCtx.createMediaStreamSource(stream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 512;
    dataArray = new Uint8Array(analyser.frequencyBinCount);
    source.connect(analyser);

    await video.play();
    resizeCanvas();
    window.addEventListener('resize', resizeCanvas);
    startFilter();
  }catch(err){
    alert('Camera/Microphone access failed: ' + err + '\n\nUse HTTPS and allow camera+mic permissions.');
  }
}

// Get audio volume (0-1)
function getVolume(){
  if (!analyser) return 0;
  analyser.getByteFrequencyData(dataArray);
  let sum=0; for (let i=0;i<dataArray.length;i++) sum += dataArray[i];
  return (sum / dataArray.length) / 255;
}

// Blink state
let blinkProgress = 1, lastBlink = Date.now(), nextBlinkIn = 2000 + Math.random()*3000;
function updateBlink(){
  const now = Date.now();
  if (now - lastBlink > nextBlinkIn){
    lastBlink = now;
    nextBlinkIn = 2000 + Math.random()*3000;
    blinkProgress = 0;
  }
  blinkProgress = lerp(blinkProgress, 1, 0.12);
  return blinkProgress;
}

// Smooth head pos
let prevNoseX=0, prevNoseY=0;

// Main render loop
async function startFilter(){
  if (!model) return;
  async function loop(){
    const preds = await model.estimateFaces({ input: video });
    ctx.clearRect(0,0,canvas.width,canvas.height);

    // Mirror video
    ctx.save();
    ctx.translate(canvas.width, 0);
    ctx.scale(-1,1);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    ctx.restore();

    if (preds.length > 0){
      const k = preds[0].scaledMesh;
      const nose = k[1], leftCheek = k[234], rightCheek = k[454], mouthCenter = k[13], forehead = k[10], leftEye = k[33], rightEye = k[263];

      const smoothNoseX = lerp(prevNoseX, nose[0], 0.3);
      const smoothNoseY = lerp(prevNoseY, nose[1], 0.3);
      prevNoseX = smoothNoseX; prevNoseY = smoothNoseY;

      const faceWidth = Math.abs(rightCheek[0]-leftCheek[0]);
      const maskWidth = faceWidth*1.4;
      const maskHeight = maskWidth*(catMask.height/Math.max(1, catMask.width));

      const toCanvasX = x => canvas.width - (x/video.videoWidth)*canvas.width;
      const toCanvasY = y => (y/video.videoHeight)*canvas.height;

      // Draw mask
      const mx = toCanvasX(smoothNoseX)-maskWidth/2;
      const my = toCanvasY(smoothNoseY)-maskHeight/2;
      ctx.drawImage(catMask, mx, my, maskWidth, maskHeight);

      // Mouth lipsync
      const volume = getVolume();
      const mouthIndex = volume > 0.05 ? Math.floor(Date.now()/150)%mouthFrames.length : 0;
      const mouthImg = mouthFrames[mouthIndex];
      const mouthW = maskWidth*0.5;
      const mouthH = mouthW*(mouthImg.height/Math.max(1, mouthImg.width));
      const mouthX = toCanvasX(mouthCenter[0])-mouthW/2;
      const mouthY = toCanvasY(mouthCenter[1])-mouthH/2 + maskHeight*0.08;
      ctx.drawImage(mouthImg, mouthX, mouthY, mouthW, mouthH);

      // Ears
      const earW = maskWidth*1.2;
      const earH = earW*(ears.height/Math.max(1, ears.width));
      const sway = Math.sin(Date.now()/450)*earH*0.08;
      const earX = toCanvasX(forehead[0])-earW/2 + sway;
      const earY = toCanvasY(forehead[1])-earH*0.9;
      ctx.drawImage(ears, earX, earY, earW, earH);

      // Eyes
      const blink = updateBlink();
      const eyeW = maskWidth*0.28;
      const eyeH = eyeW*(eyes.height/Math.max(1, eyes.width))*blink;
      const lEx = toCanvasX(leftEye[0])-eyeW/2;
      const rEx = toCanvasX(rightEye[0])-eyeW/2;
      const eY = (toCanvasY(leftEye[1])+toCanvasY(rightEye[1]))/2-eyeH/2;
      ctx.drawImage(eyes, lEx, eY, eyeW, eyeH);
      ctx.drawImage(eyes, rEx, eY, eyeW, eyeH);
    }

    animationFrame = requestAnimationFrame(loop);
  }
  loop();
}

// Controls
document.getElementById('start').addEventListener('click', ()=>{
  if (!mediaRecorder) return alert('Recorder not ready yet');
  if (!recording){ mediaRecorder.start(); recording=true; }
  else {
    if (mediaRecorder.state==='recording') mediaRecorder.pause();
    else mediaRecorder.resume();
  }
});

document.getElementById('stop').addEventListener('click', ()=>{
  if (recording) mediaRecorder.stop();
  recording=false;
  cancelAnimationFrame(animationFrame);
});

function downloadVideo(){
  const blob = new Blob(recordedChunks, { type:'video/webm' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a'); a.href=url; a.download='catface.webm';
  document.body.appendChild(a); a.click(); a.remove();
  recordedChunks=[];
}

// Initialize
loadModel().then(initCameraAndAudio);
</script>
</body>
</html>
