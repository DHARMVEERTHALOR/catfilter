<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Ultimate Smooth Cat Face Filter</title>
<style>
body { margin:0; background:#000; display:flex; justify-content:center; align-items:center; height:100vh; overflow:hidden; }
canvas { position:absolute; top:0; left:0; }
#controls { position:fixed; bottom:20px; left:50%; transform:translateX(-50%); display:flex; gap:10px; z-index:1000; }
button { padding:10px 16px; font-size:15px; border:none; border-radius:10px; background:#ff8fb3; color:#fff; cursor:pointer; box-shadow:0 4px 12px rgba(0,0,0,0.4); }
button:disabled { opacity:0.5; cursor:not-allowed; }
#message { position:fixed; top:12px; left:12px; color:#fff; font-family:system-ui,Segoe UI,Roboto,Arial; background:rgba(0,0,0,0.4); padding:8px 12px; border-radius:8px; }
</style>
</head>
<body>

<div id="message">Allow camera & mic when prompted. Best on HTTPS.</div>
<video id="video" autoplay playsinline style="display:none;"></video>
<canvas id="canvas"></canvas>

<div id="controls">
  <button id="start" disabled>Start/Pause</button>
  <button id="stop">Stop & Download</button>
</div>

<!-- TensorFlow.js & Face Landmarks Detection -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
let stream, animationFrame, recording=false, mediaRecorder, recordedChunks=[], model;
let audioCtx, analyser, dataArray;

// Images
const catMask = new Image(); catMask.src = 'cat-mask.png';
const mouthFrames = []; for (let i=1;i<=3;i++){ const img=new Image(); img.src=`mouth${i}.png`; mouthFrames.push(img); }
const ears = new Image(); ears.src = 'ears.png';
const eyes = new Image(); eyes.src = 'eyes.png';

// Utility
function lerp(a,b,t){ return a + (b-a)*t; }

// Resize canvas to fit viewport maintaining 9:16
function resizeCanvas(){
  const vw = window.innerWidth;
  const vh = window.innerHeight;
  let canvasWidth = vw;
  let canvasHeight = vh;

  if (vw/vh > 9/16) canvasWidth = vh*(9/16);
  else canvasHeight = vw*(16/9);

  canvas.width = canvasWidth;
  canvas.height = canvasHeight;
}

// Load face model
async function loadModel(){
  model = await faceLandmarksDetection.load(
    faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh,
    { maxFaces: 1 }
  );
}

// Init camera + audio
async function initCameraAndAudio(){
  try{
    stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode:'user', width:480, height:854 },
      audio: true
    });
    video.srcObject = stream;
    await video.play();
    resizeCanvas();
    window.addEventListener('resize', resizeCanvas);

    let mime = 'video/webm';
    if (!MediaRecorder.isTypeSupported(mime)) mime = 'video/mp4';
    mediaRecorder = new MediaRecorder(stream, { mimeType: mime });
    mediaRecorder.ondataavailable = e => { if (e.data.size>0) recordedChunks.push(e.data); };
    mediaRecorder.onstop = downloadVideo;

    document.getElementById('start').disabled = false;

    startFilter();

  } catch(err){
    alert('Camera/Microphone access failed: ' + err + '\nUse HTTPS and allow camera+mic permissions.');
  }
}

// Audio volume
function getVolume(){
  if (!analyser) return 0;
  analyser.getByteFrequencyData(dataArray);
  let sum=0; for (let i=0;i<dataArray.length;i++) sum += dataArray[i];
  return (sum / dataArray.length) / 255;
}

// Blink
let blinkProgress = 1, lastBlink = Date.now(), nextBlinkIn = 2000 + Math.random()*3000;
function updateBlink(){
  const now = Date.now();
  if (now - lastBlink > nextBlinkIn){
    lastBlink = now;
    nextBlinkIn = 2000 + Math.random()*3000;
    blinkProgress = 0;
  }
  blinkProgress = lerp(blinkProgress, 1, 0.12);
  return blinkProgress;
}

// Smooth head pos
let prevNoseX=0, prevNoseY=0;

// Main loop
async function startFilter(){
  if (!model) return;
  async function loop(){
    const preds = await model.estimateFaces({ input: video });
    ctx.clearRect(0,0,canvas.width,canvas.height);

    // Mirror video
    ctx.save();
    ctx.translate(canvas.width, 0);
    ctx.scale(-1,1);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    ctx.restore();

    if (preds.length>0){
      const k = preds[0].scaledMesh;
      const nose = k[1], leftCheek = k[234], rightCheek = k[454], mouthCenter = k[13], forehead = k[10], leftEye = k[33], rightEye = k[263];

      const smoothNoseX = lerp(prevNoseX, nose[0], 0.3);
      const smoothNoseY = lerp(prevNoseY, nose[1], 0.3);
      prevNoseX = smoothNoseX; prevNoseY = smoothNoseY;

      const faceWidth = Math.abs(rightCheek[0]-leftCheek[0]);
      const maskWidth = faceWidth*1.4;
      const maskHeight = maskWidth*(catMask.height/Math.max(1, catMask.width));

      const toCanvasX = x => canvas.width - (x/video.videoWidth)*canvas.width;
      const toCanvasY = y => (y/video.videoHeight)*canvas.height;

      // Draw mask
      ctx.drawImage(catMask, toCanvasX(smoothNoseX)-maskWidth/2, toCanvasY(smoothNoseY)-maskHeight/2, maskWidth, maskHeight);

      // Mouth lipsync
      const volume = getVolume();
      const mouthIndex = volume > 0.05 ? Math.floor(Date.now()/150)%mouthFrames.length : 0;
      const mouthImg = mouthFrames[mouthIndex];
      const mouthW = maskWidth*0.5;
      const mouthH = mouthW*(mouthImg.height/Math.max(1, mouthImg.width));
      ctx.drawImage(mouthImg, toCanvasX(mouthCenter[0])-mouthW/2, toCanvasY(mouthCenter[1])-mouthH/2+maskHeight*0.08, mouthW, mouthH);

      // Ears
      const earW = maskWidth*1.2;
      const earH = earW*(ears.height/Math.max(1, ears.width));
      const sway = Math.sin(Date.now()/450)*earH*0.08;
      ctx.drawImage(ears, toCanvasX(forehead[0])-earW/2+sway, toCanvasY(forehead[1])-earH*0.9, earW, earH);

      // Eyes
      const blink = updateBlink();
      const eyeW = maskWidth*0.28;
      const eyeH = eyeW*(eyes.height/Math.max(1, eyes.width))*blink;
      ctx.drawImage(eyes, toCanvasX(leftEye[0])-eyeW/2, (toCanvasY(leftEye[1])+toCanvasY(rightEye[1]))/2-eyeH/2, eyeW, eyeH);
      ctx.drawImage(eyes, toCanvasX(rightEye[0])-eyeW/2, (toCanvasY(leftEye[1])+toCanvasY(rightEye[1]))/2-eyeH/2, eyeW, eyeH);
    }

    animationFrame = requestAnimationFrame(loop);
  }
  loop();
}

// Controls
const startBtn = document.getElementById('start');
startBtn.addEventListener('click', ()=>{
  if (!mediaRecorder) return;
  if (!recording){ mediaRecorder.start(); recording=true; }
  else { if (mediaRecorder.state==='recording') mediaRecorder.pause(); else mediaRecorder.resume(); }
});

document.getElementById('stop').addEventListener('click', ()=>{
  if (recording) mediaRecorder.stop();
  recording=false;
  cancelAnimationFrame(animationFrame);
});

function downloadVideo(){
  const blob = new Blob(recordedChunks, { type:'video/webm' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a'); a.href=url; a.download='catface.webm';
  document.body.appendChild(a); a.click(); a.remove();
  recordedChunks=[];
}

// Initialize
loadModel().then(initCameraAndAudio);
</script>
</body>
</html>
