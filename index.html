<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Ultimate Smooth Cat Face Filter</title>
<style>
body { margin:0; background:#000; display:flex; justify-content:center; align-items:center; height:100vh; overflow:hidden; }
canvas { position:absolute; top:0; left:0; }
#controls { position:fixed; bottom:20px; left:50%; transform:translateX(-50%); display:flex; gap:10px; z-index:1000; }
button { padding:10px 16px; font-size:15px; border:none; border-radius:10px; background:#ff8fb3; color:#fff; cursor:pointer; box-shadow:0 4px 12px rgba(0,0,0,0.4); }
#message { position:fixed; top:12px; left:12px; color:#fff; font-family:system-ui,Segoe UI,Roboto,Arial; background:rgba(0,0,0,0.4); padding:8px 12px; border-radius:8px; }
</style>
</head>
<body>

<div id="message">Allow camera & mic when prompted. Best on HTTPS.</div>
<video id="video" autoplay playsinline style="display:none;"></video>
<canvas id="canvas"></canvas>

<div id="controls">
  <button id="start">Start/Pause</button>
  <button id="stop">Stop & Download</button>
</div>

<script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');

let stream, animationFrame, recording=false, mediaRecorder, recordedChunks=[];
let audioCtx, analyser, dataArray;
let blinkProgress=1, lastBlink=Date.now(), nextBlinkIn=2000+Math.random()*3000;
let prevNoseX=0, prevNoseY=0;

// Images
const catMask = new Image(); catMask.src='cat-mask.png';
const mouthFrames=[]; for(let i=1;i<=3;i++){ const img=new Image(); img.src=`mouth${i}.png`; mouthFrames.push(img); }
const ears=new Image(); ears.src='ears.png';
const eyes=new Image(); eyes.src='eyes.png';

// lerp
function lerp(a,b,t){ return a + (b-a)*t; }

// Canvas resize
function resizeCanvas(){
    canvas.width = video.videoWidth || 480;
    canvas.height = video.videoHeight || 854;
    if(!video.videoWidth){
        canvas.width = Math.min(window.innerWidth,480);
        canvas.height = Math.round(canvas.width*16/9);
    }
}

// Load face-api.js models
async function loadModels(){
    await Promise.all([
        faceapi.nets.ssdMobilenetv1.loadFromUri('/models'),
        faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
        faceapi.nets.faceExpressionNet.loadFromUri('/models')
    ]);
    initCameraAndAudio();
}

// Initialize camera and audio
async function initCameraAndAudio(){
    try{
        stream = await navigator.mediaDevices.getUserMedia({ video:{ facingMode:'user', width:480, height:854 }, audio:true });
        video.srcObject = stream;
        await video.play();
        resizeCanvas();
        window.addEventListener('resize', resizeCanvas);

        // Media Recorder
        mediaRecorder = new MediaRecorder(stream,{mimeType:'video/webm'});
        mediaRecorder.ondataavailable = e => { if(e.data.size>0) recordedChunks.push(e.data); };
        mediaRecorder.onstop = downloadVideo;

        // Audio analyser
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const source = audioCtx.createMediaStreamSource(stream);
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 512;
        dataArray = new Uint8Array(analyser.frequencyBinCount);
        source.connect(analyser);

        startFilter();
    }catch(err){
        alert('Camera/Microphone access failed: '+err);
    }
}

// Audio volume 0-1
function getVolume(){
    if(!analyser) return 0;
    analyser.getByteFrequencyData(dataArray);
    let sum=0; for(let i=0;i<dataArray.length;i++) sum+=dataArray[i];
    return (sum/dataArray.length)/255;
}

// Blink update
function updateBlink(){
    const now=Date.now();
    if(now-lastBlink>nextBlinkIn){ lastBlink=now; nextBlinkIn=2000+Math.random()*3000; blinkProgress=0; }
    blinkProgress = lerp(blinkProgress,1,0.12);
    return blinkProgress;
}

// Main loop
async function startFilter(){
    async function loop(){
        const detections = await faceapi.detectSingleFace(video).withFaceLandmarks().withFaceExpressions();
        ctx.clearRect(0,0,canvas.width,canvas.height);

        // Mirror video
        ctx.save();
        ctx.translate(canvas.width,0);
        ctx.scale(-1,1);
        ctx.drawImage(video,0,0,canvas.width,canvas.height);
        ctx.restore();

        if(detections){
            const k = detections.landmarks.positions;
            const nose = k[30], leftCheek=k[2], rightCheek=k[14], mouthCenter=k[62], forehead=k[24], leftEye=k[36], rightEye=k[45];

            // Smooth nose
            const smoothNoseX = lerp(prevNoseX,nose.x,0.3);
            const smoothNoseY = lerp(prevNoseY,nose.y,0.3);
            prevNoseX=smoothNoseX; prevNoseY=smoothNoseY;

            const faceWidth = Math.abs(rightCheek.x-leftCheek.x);
            const maskWidth = faceWidth*1.4;
            const maskHeight = maskWidth*(catMask.height/Math.max(1,catMask.width));

            const toCanvasX = x=>canvas.width - (x/video.videoWidth)*canvas.width;
            const toCanvasY = y=> (y/video.videoHeight)*canvas.height;

            // Draw mask
            const mx = toCanvasX(smoothNoseX)-maskWidth/2;
            const my = toCanvasY(smoothNoseY)-maskHeight/2;
            ctx.drawImage(catMask,mx,my,maskWidth,maskHeight);

            // Mouth lipsync
            const volume=getVolume();
            const mouthIndex = volume>0.05 ? Math.floor(Date.now()/150)%mouthFrames.length : 0;
            const mouthImg = mouthFrames[mouthIndex];
            const mouthW = maskWidth*0.5;
            const mouthH = mouthW*(mouthImg.height/Math.max(1,mouthImg.width));
            const mouthX = toCanvasX(mouthCenter.x)-mouthW/2;
            const mouthY = toCanvasY(mouthCenter.y)-mouthH/2+maskHeight*0.08;
            ctx.drawImage(mouthImg,mouthX,mouthY,mouthW,mouthH);

            // Ears sway
            const earW = maskWidth*1.2;
            const earH = earW*(ears.height/Math.max(1,ears.width));
            const sway = Math.sin(Date.now()/450)*earH*0.08;
            const earX = toCanvasX(forehead.x)-earW/2+sway;
            const earY = toCanvasY(forehead.y)-earH*0.9;
            ctx.drawImage(ears,earX,earY,earW,earH);

            // Eyes blink
            const blink=updateBlink();
            const eyeW = maskWidth*0.28;
            const eyeH = eyeW*(eyes.height/Math.max(1,eyes.width))*blink;
            const lEx=toCanvasX(leftEye.x)-eyeW/2;
            const rEx=toCanvasX(rightEye.x)-eyeW/2;
            const eY=(toCanvasY(leftEye.y)+toCanvasY(rightEye.y))/2 - eyeH/2;
            ctx.drawImage(eyes,lEx,eY,eyeW,eyeH);
            ctx.drawImage(eyes,rEx,eY,eyeW,eyeH);
        }

        animationFrame=requestAnimationFrame(loop);
    }
    loop();
}

// Controls
document.getElementById('start').addEventListener('click',()=>{
    if(!mediaRecorder) return alert('Recorder not ready yet');
    if(!recording){ mediaRecorder.start(); recording=true; }
    else {
        if(mediaRecorder.state==='recording') mediaRecorder.pause();
        else mediaRecorder.resume();
    }
});

document.getElementById('stop').addEventListener('click',()=>{
    if(recording) mediaRecorder.stop();
    recording=false;
    cancelAnimationFrame(animationFrame);
});

function downloadVideo(){
    const blob=new Blob(recordedChunks,{type:'video/webm'});
    const url=URL.createObjectURL(blob);
    const a=document.createElement('a');
    a.href=url;
    a.download='catface.webm';
    document.body.appendChild(a);
    a.click();
    a.remove();
    recordedChunks=[];
}

// Start
loadModels();
</script>

</body>
</html>
